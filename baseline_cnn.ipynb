{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"color: #FF0000;\">Baseline Model: Implementation and Rationale</span>\n",
    "\n",
    "##### <span style=\"color: #1E90FF;\">1. Goal of the Baseline</span>\n",
    "\n",
    "The aim of our baseline model was to quickly establish a from-scratch convolutional network to confirm our dataset loading, shape consistency, and minimal data augmentation pipeline. By building a small \"two-block CNN,\" we gain an early reference point (both in accuracy and training behavior) before applying more sophisticated or pretrained approaches.\n",
    "\n",
    "##### <span style=\"color: #1E90FF;\">2. Architectural Decisions</span>\n",
    "\n",
    "- **Input Shape**: (180,180,3) to align with image_dataset_from_directory(..., image_size=(180,180))\n",
    "- **Two Convolution Blocks**:\n",
    "  - Each block has Conv2D(32,3) or Conv2D(64,3) repeated twice, then a MaxPooling2D\n",
    "  - This standard pattern follows a typical VGG-like design, albeit in a smaller scale\n",
    "- **Flatten → Dense**:\n",
    "  - We flatten the pooled feature maps, then apply a Dense(128, relu) with a Dropout(0.5) for partial regularization\n",
    "  - Lastly, a Dense(num_classes, softmax) for multi-class classification\n",
    "\n",
    "##### <span style=\"color: #1E90FF;\">3. Data Augmentation</span>\n",
    "\n",
    "Before the first convolution block, we incorporate Keras's built-in augmentation layers:\n",
    "- RandomFlip horizontally\n",
    "- RandomRotation ~10%\n",
    "- RandomZoom ~10%\n",
    "\n",
    "These transformations help the model learn invariance to flips, minor rotation, and scale changes, presumably beneficial given our limited dataset sizes (~100–172 images per class).\n",
    "\n",
    "##### <span style=\"color: #1E90FF;\">4. Key Observations from Training</span>\n",
    "\n",
    "- **Fluctuating Loss**: The training loss sometimes dips, then spikes. This can be symptomatic of a somewhat high learning rate or an architecture that is quickly overfitting in certain epochs\n",
    "- **Reasonable Test Accuracy**: (~77–80%) by the final epoch, demonstrating that even a modest CNN can differentiate the classes with moderate reliability\n",
    "- **Overfitting Tendency**: Our training accuracy occasionally outstripped validation, but data augmentation plus dropout helps mitigate it, showing a measure of stability\n",
    "\n",
    "##### <span style=\"color: #1E90FF;\">5. Future Enhancements</span>\n",
    "\n",
    "- **Hyperparameter Tuning**: Investigate a smaller or variable learning rate, or experiment with an additional conv block for deeper feature extraction\n",
    "- **Transfer Learning**: As recommended in our roadmap, consider using a pretrained network (e.g., VGG16 or MobileNet). This often boosts accuracy for small or moderate datasets\n",
    "- **Offline Augmentation**: Potentially expand the dataset with the separate offline augmentation script—generating more samples to reduce overfitting\n",
    "\n",
    "##### <span style=\"color: #1E90FF;\">6. Conclusion and Next Steps</span>\n",
    "\n",
    "The baseline model proves that a simple two-block CNN, plus minimal on-the-fly augmentation, yields a workable solution. This foundation is well-suited for iterative refinement—either by adjusting hyperparameters or transitioning to a more advanced Transfer Learning pipeline—as guided by our overall project roadmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tensorflow\n",
    "%pip install matplotlib\n",
    "%pip install numpy\n",
    "%pip install scikit-learn   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# baseline_implementation_no_dip.py\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "###########################################################################\n",
    "# Data Augmentation Pipeline\n",
    "###########################################################################\n",
    "myDataAug = keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom(0.1),\n",
    "    # You can add layers.RandomContrast(0.1) if desired.\n",
    "], name=\"MyDataAug\")\n",
    "\n",
    "###########################################################################\n",
    "# Baseline CNN Model: repeated 3×3 conv + maxpool\n",
    "###########################################################################\n",
    "def build_baseline_cnn(num_classes=3, input_shape=(180,180,3)):\n",
    "    \"\"\"\n",
    "    Basic CNN: repeated 3x3 conv -> maxpool -> flatten -> dense.\n",
    "    \"\"\"\n",
    "    # The input shape is (180,180,3) to match your dataset resizing\n",
    "    inputs = keras.Input(shape=input_shape, name=\"input_image\")\n",
    "\n",
    "    # (Optional) Data augmentation first\n",
    "    x = myDataAug(inputs)\n",
    "\n",
    "    # 1st conv block\n",
    "    x = layers.Conv2D(32, kernel_size=3, padding='same', activation='relu')(x)\n",
    "    x = layers.Conv2D(32, kernel_size=3, padding='same', activation='relu')(x)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "\n",
    "    # 2nd conv block\n",
    "    x = layers.Conv2D(64, kernel_size=3, padding='same', activation='relu')(x)\n",
    "    x = layers.Conv2D(64, kernel_size=3, padding='same', activation='relu')(x)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "\n",
    "    # (Optional) 3rd conv block\n",
    "    # x = layers.Conv2D(128, kernel_size=3, padding='same', activation='relu')(x)\n",
    "    # x = layers.Conv2D(128, kernel_size=3, padding='same', activation='relu')(x)\n",
    "    # x = layers.MaxPooling2D()(x)\n",
    "\n",
    "    # Flatten and dense\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    model = keras.Model(inputs, outputs, name=\"BaselineCNN\")\n",
    "    return model\n",
    "\n",
    "###########################################################################\n",
    "# Main\n",
    "###########################################################################\n",
    "def main():\n",
    "    # 1) Paths\n",
    "    train_dir = \"/Users/ryangichuru/Documents/SSD-K/Uni/2nd year/Intro to AI/CNN/assignment-2-ryantigi254-main/data/Output Data/train\"\n",
    "    val_dir   = \"/Users/ryangichuru/Documents/SSD-K/Uni/2nd year/Intro to AI/CNN/assignment-2-ryantigi254-main/data/Output Data/val\"\n",
    "    test_dir  = \"/Users/ryangichuru/Documents/SSD-K/Uni/2nd year/Intro to AI/CNN/assignment-2-ryantigi254-main/data/Output Data/test\"\n",
    "\n",
    "    # 2) Load Datasets\n",
    "    batch_size = 32\n",
    "    img_size = (180, 180)\n",
    "\n",
    "    train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        train_dir,\n",
    "        image_size=img_size,\n",
    "        batch_size=batch_size,\n",
    "        label_mode='categorical'\n",
    "    )\n",
    "    val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        val_dir,\n",
    "        image_size=img_size,\n",
    "        batch_size=batch_size,\n",
    "        label_mode='categorical'\n",
    "    )\n",
    "    test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        test_dir,\n",
    "        image_size=img_size,\n",
    "        batch_size=batch_size,\n",
    "        label_mode='categorical'\n",
    "    )\n",
    "\n",
    "    # 3) Build model\n",
    "    num_classes = 3  # e.g. 3 people or classes\n",
    "    baseline_model = build_baseline_cnn(num_classes=num_classes,\n",
    "                                        input_shape=(180,180,3))\n",
    "    baseline_model.summary()\n",
    "\n",
    "    # 4) Compile\n",
    "    baseline_model.compile(optimizer='rmsprop',\n",
    "                           loss='categorical_crossentropy',\n",
    "                           metrics=['accuracy'])\n",
    "\n",
    "    # 5) Train\n",
    "    callbacks_list = [\n",
    "        keras.callbacks.ModelCheckpoint(\"baseline_cnn_best.h5\",\n",
    "                                        save_best_only=True,\n",
    "                                        monitor=\"val_loss\")\n",
    "    ]\n",
    "    epochs = 10\n",
    "    history = baseline_model.fit(\n",
    "        train_ds,\n",
    "        validation_data=val_ds,\n",
    "        epochs=epochs,\n",
    "        callbacks=callbacks_list\n",
    "    )\n",
    "\n",
    "    # 6) Evaluate on test set\n",
    "    print(\"\\nEvaluating on test set ...\")\n",
    "    test_loss, test_acc = baseline_model.evaluate(test_ds)\n",
    "    print(f\"Test loss: {test_loss:.4f}\")\n",
    "    print(f\"Test accuracy: {test_acc:.4f}\")\n",
    "\n",
    "    # 7) Plot training vs. validation\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs_range = range(1, len(acc)+1)\n",
    "\n",
    "    plt.figure(figsize=(12,5))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(epochs_range, acc, 'bo-', label='Training Acc')\n",
    "    plt.plot(epochs_range, val_acc, 'ro-', label='Validation Acc')\n",
    "    plt.title('Training & Validation Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(epochs_range, loss, 'bo-', label='Training Loss')\n",
    "    plt.plot(epochs_range, val_loss, 'ro-', label='Validation Loss')\n",
    "    plt.title('Training & Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # 8) Confusion Matrix\n",
    "    print(\"\\nGenerating confusion matrix ...\")\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    for images, labels in test_ds:\n",
    "        preds = baseline_model.predict(images)\n",
    "        all_preds.extend(tf.argmax(preds, axis=1).numpy())\n",
    "        all_labels.extend(tf.argmax(labels, axis=1).numpy())\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix, classification_report\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    print(\"Confusion Matrix:\\n\", cm)\n",
    "    print(\"Classification Report:\\n\", \n",
    "          classification_report(all_labels, all_preds))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlx-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
