{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"color: #FF0000;\">Overview of the Process</span>\n",
    "\n",
    "This section focuses on data preparation for a robust face detection and quality control measures using OpenCV's Haar Cascade classifier, MTCNN and custom sampling techniques. The goal is to ensure consistent image quality and proper facial feature representation across the dataset.\n",
    "\n",
    "##### <span style=\"color: #1E90FF;\">Key Components</span>\n",
    "\n",
    "1. **Detection Pipeline**:\n",
    "   - OpenCV Haar Cascade face detection - Fast and efficient face detection using pre-trained cascade classifiers\n",
    "   - Custom sampling methodology \n",
    "   - Quality verification system\n",
    "\n",
    "2. **Quality Control Process**:\n",
    "   - Sample 15 images per person (5 start/middle/end)\n",
    "   - Face detection confidence thresholds\n",
    "   - Manual review flagging system\n",
    "\n",
    "3. **Technical Requirements**:\n",
    "   - Centered facial features\n",
    "   - Consistent lighting/background\n",
    "   - Standardized dimensions\n",
    "   - Clear facial visibility\n",
    "\n",
    "4. **Verification Steps**:\n",
    "   - Automated face detection checks\n",
    "   - Sample image visual inspection\n",
    "   - Systematic issue identification\n",
    "   - Quality metrics logging\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert images from HEIC to JPG format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from pillow_heif import register_heif_opener\n",
    "from PIL import Image\n",
    "register_heif_opener()\n",
    "\n",
    "def convert_heic_to_jpg(base_path):\n",
    "    # Get all HEIC files (case insensitive)\n",
    "    heic_images = [f for f in os.listdir(base_path) if f.lower().endswith(('.heic'))]\n",
    "    converted_count = 0\n",
    "    \n",
    "    for img in heic_images:\n",
    "        heic_path = os.path.join(base_path, img)\n",
    "        jpg_path = os.path.splitext(heic_path)[0] + '.jpg'\n",
    "        \n",
    "        try:\n",
    "            with Image.open(heic_path) as i:\n",
    "                i.convert('RGB').save(jpg_path, 'JPEG', quality=95)\n",
    "            print(f\"Converted {img} to JPG\")\n",
    "            converted_count += 1\n",
    "            # Remove original HEIC file after successful conversion\n",
    "            os.remove(heic_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error converting {img}: {e}\")\n",
    "    \n",
    "    print(f\"Converted {converted_count} images\")\n",
    "\n",
    "def organize_user_images(base_path):\n",
    "    # Get all JPG images\n",
    "    images = [f for f in os.listdir(base_path) if f.lower().endswith('.jpg')]\n",
    "    user = os.path.basename(base_path)\n",
    "    \n",
    "    for idx, img in enumerate(images, 1):\n",
    "        subfolder_name = f\"{user}_{idx}\"\n",
    "        subfolder_path = os.path.join(base_path, subfolder_name)\n",
    "        os.makedirs(subfolder_path, exist_ok=True)\n",
    "        \n",
    "        old_img_path = os.path.join(base_path, img)\n",
    "        new_img_name = f\"{subfolder_name}.jpg\"\n",
    "        new_img_path = os.path.join(subfolder_path, new_img_name)\n",
    "        shutil.move(old_img_path, new_img_path)\n",
    "\n",
    "def process_all_users(paths):\n",
    "    for path in paths:\n",
    "        print(f\"\\nProcessing {path}\")\n",
    "        convert_heic_to_jpg(path)\n",
    "        organize_user_images(path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    paths = [\n",
    "        \"/Users/ryangichuru/Documents/SSD-K/Uni/2nd year/Intro to AI/CNN/assignment-2-ryantigi254-main/data/enhanced data/Ryan\",\n",
    "        \"/Users/ryangichuru/Documents/SSD-K/Uni/2nd year/Intro to AI/CNN/assignment-2-ryantigi254-main/data/enhanced data/Saurish\"\n",
    "    ]\n",
    "    process_all_users(paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"color: #FF0000;\">1. Data Organization</span>\n",
    "\n",
    "The goal is to organize our image data through several key steps:\n",
    "- Converting HEIC images to JPG format for compatibility (Based on code from: https://stackoverflow.com/questions/54395735/how-to-work-with-heic-image-file-types-in-python)\n",
    "- Creating individual folders to store each image separately\n",
    "- Organizing images into user-specific directories for better structure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "def organize_user_images():\n",
    "    # Base directory where user folders are located\n",
    "    base_dir = \"Original Data\"\n",
    "    \n",
    "    # Get all user directories\n",
    "    user_dirs = [d for d in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, d))]\n",
    "    \n",
    "    for user in user_dirs:\n",
    "        user_path = os.path.join(base_dir, user)\n",
    "        # Get all images in user directory\n",
    "        images = [f for f in os.listdir(user_path) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.gif'))]\n",
    "        \n",
    "        # Create numbered subfolders and move images\n",
    "        for idx, img in enumerate(images, 1):\n",
    "            # Create subfolder name (e.g., \"john_1\")\n",
    "            subfolder_name = f\"{user}_{idx}\"\n",
    "            subfolder_path = os.path.join(user_path, subfolder_name)\n",
    "            \n",
    "            # Create subfolder if it doesn't exist\n",
    "            os.makedirs(subfolder_path, exist_ok=True)\n",
    "            \n",
    "            # Get image extension\n",
    "            _, ext = os.path.splitext(img)\n",
    "            \n",
    "            # New image name will match subfolder name\n",
    "            new_img_name = f\"{subfolder_name}{ext}\"\n",
    "            \n",
    "            # Move and rename image\n",
    "            old_img_path = os.path.join(user_path, img)\n",
    "            new_img_path = os.path.join(subfolder_path, new_img_name)\n",
    "            shutil.move(old_img_path, new_img_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    organize_user_images()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Environment Setup and Hardware Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mlx in /opt/homebrew/Caskroom/miniforge/base/envs/mlx-env/lib/python3.12/site-packages (0.22.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: tensorflow in /opt/homebrew/Caskroom/miniforge/base/envs/mlx-env/lib/python3.12/site-packages (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/homebrew/Caskroom/miniforge/base/envs/mlx-env/lib/python3.12/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/homebrew/Caskroom/miniforge/base/envs/mlx-env/lib/python3.12/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /opt/homebrew/Caskroom/miniforge/base/envs/mlx-env/lib/python3.12/site-packages (from tensorflow) (24.12.23)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/homebrew/Caskroom/miniforge/base/envs/mlx-env/lib/python3.12/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/homebrew/Caskroom/miniforge/base/envs/mlx-env/lib/python3.12/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/homebrew/Caskroom/miniforge/base/envs/mlx-env/lib/python3.12/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/homebrew/Caskroom/miniforge/base/envs/mlx-env/lib/python3.12/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in /opt/homebrew/Caskroom/miniforge/base/envs/mlx-env/lib/python3.12/site-packages (from tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /opt/homebrew/Caskroom/miniforge/base/envs/mlx-env/lib/python3.12/site-packages (from tensorflow) (5.29.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/homebrew/Caskroom/miniforge/base/envs/mlx-env/lib/python3.12/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /opt/homebrew/Caskroom/miniforge/base/envs/mlx-env/lib/python3.12/site-packages (from tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/homebrew/Caskroom/miniforge/base/envs/mlx-env/lib/python3.12/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/homebrew/Caskroom/miniforge/base/envs/mlx-env/lib/python3.12/site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/homebrew/Caskroom/miniforge/base/envs/mlx-env/lib/python3.12/site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/homebrew/Caskroom/miniforge/base/envs/mlx-env/lib/python3.12/site-packages (from tensorflow) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/homebrew/Caskroom/miniforge/base/envs/mlx-env/lib/python3.12/site-packages (from tensorflow) (1.69.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in /opt/homebrew/Caskroom/miniforge/base/envs/mlx-env/lib/python3.12/site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in /opt/homebrew/Caskroom/miniforge/base/envs/mlx-env/lib/python3.12/site-packages (from tensorflow) (3.8.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /opt/homebrew/Caskroom/miniforge/base/envs/mlx-env/lib/python3.12/site-packages (from tensorflow) (2.0.2)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /opt/homebrew/Caskroom/miniforge/base/envs/mlx-env/lib/python3.12/site-packages (from tensorflow) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /opt/homebrew/Caskroom/miniforge/base/envs/mlx-env/lib/python3.12/site-packages (from tensorflow) (0.4.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/homebrew/Caskroom/miniforge/base/envs/mlx-env/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: rich in /opt/homebrew/Caskroom/miniforge/base/envs/mlx-env/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in /opt/homebrew/Caskroom/miniforge/base/envs/mlx-env/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /opt/homebrew/Caskroom/miniforge/base/envs/mlx-env/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/Caskroom/miniforge/base/envs/mlx-env/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/Caskroom/miniforge/base/envs/mlx-env/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/Caskroom/miniforge/base/envs/mlx-env/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/Caskroom/miniforge/base/envs/mlx-env/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/homebrew/Caskroom/miniforge/base/envs/mlx-env/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/homebrew/Caskroom/miniforge/base/envs/mlx-env/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/homebrew/Caskroom/miniforge/base/envs/mlx-env/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/homebrew/Caskroom/miniforge/base/envs/mlx-env/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/homebrew/Caskroom/miniforge/base/envs/mlx-env/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/homebrew/Caskroom/miniforge/base/envs/mlx-env/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/homebrew/Caskroom/miniforge/base/envs/mlx-env/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: numpy in /opt/homebrew/Caskroom/miniforge/base/envs/mlx-env/lib/python3.12/site-packages (2.0.2)\n",
      "Requirement already satisfied: matplotlib in /opt/homebrew/Caskroom/miniforge/base/envs/mlx-env/lib/python3.12/site-packages (3.10.0)\n",
      "Requirement already satisfied: opencv-python in /opt/homebrew/Caskroom/miniforge/base/envs/mlx-env/lib/python3.12/site-packages (4.11.0.86)\n",
      "Requirement already satisfied: scikit-learn in /opt/homebrew/Caskroom/miniforge/base/envs/mlx-env/lib/python3.12/site-packages (1.6.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/homebrew/Caskroom/miniforge/base/envs/mlx-env/lib/python3.12/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/homebrew/Caskroom/miniforge/base/envs/mlx-env/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/homebrew/Caskroom/miniforge/base/envs/mlx-env/lib/python3.12/site-packages (from matplotlib) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/homebrew/Caskroom/miniforge/base/envs/mlx-env/lib/python3.12/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/homebrew/Caskroom/miniforge/base/envs/mlx-env/lib/python3.12/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /opt/homebrew/Caskroom/miniforge/base/envs/mlx-env/lib/python3.12/site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/homebrew/Caskroom/miniforge/base/envs/mlx-env/lib/python3.12/site-packages (from matplotlib) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/homebrew/Caskroom/miniforge/base/envs/mlx-env/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/homebrew/Caskroom/miniforge/base/envs/mlx-env/lib/python3.12/site-packages (from scikit-learn) (1.15.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/homebrew/Caskroom/miniforge/base/envs/mlx-env/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/homebrew/Caskroom/miniforge/base/envs/mlx-env/lib/python3.12/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/Caskroom/miniforge/base/envs/mlx-env/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install mlx\n",
    "%pip install tensorflow\n",
    "\n",
    "# Install other dependencies\n",
    "%pip install numpy matplotlib opencv-python scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLX Metal available: True\n"
     ]
    }
   ],
   "source": [
    "import mlx.core as mx\n",
    "import mlx.nn as nn\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Check if MLX can use Metal backend\n",
    "print(f\"MLX Metal available: {mx.metal.is_available()}\")\n",
    "\n",
    "# For TensorFlow, limit to CPU if on Apple Silicon\n",
    "tf.config.set_visible_devices([], 'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.18.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ## 3. Data Preparation and Face Detection\n",
    "\n",
    "##### <span style=\"color: #FF0000;\">Overview of the Process</span>\n",
    "\n",
    "This section focuses on implementing robust face detection and quality control measures using OpenCV's Haar Cascade classifier and custom sampling techniques. The goal is to ensure consistent image quality and proper facial feature representation across the dataset.\n",
    "\n",
    "##### <span style=\"color: #1E90FF;\">Key Components</span>\n",
    "\n",
    "1. **Detection Pipeline**:\n",
    "   - OpenCV Haar Cascade face detection [1][2] - Fast and efficient face detection using pre-trained cascade classifiers\n",
    "      (https://docs.opencv.org/4.x/db/d28/tutorial_cascade_classifier.html)\n",
    "      (https://docs.opencv.org/3.4.1/d7/d8b/tutorial_py_face_detection.html)\n",
    "   - Custom sampling methodology\n",
    "   - Quality verification system\n",
    "\n",
    "2. **Quality Control Process**:\n",
    "   - Sample 15 images per person (5 start/middle/end)\n",
    "   - Face detection confidence thresholds\n",
    "   - Manual review flagging system\n",
    "\n",
    "3. **Technical Requirements**:\n",
    "   - Centered facial features\n",
    "   - Consistent lighting/background\n",
    "   - Standardized dimensions\n",
    "   - Clear facial visibility\n",
    "\n",
    "4. **Verification Steps**:\n",
    "   - Automated face detection checks\n",
    "   - Sample image visual inspection\n",
    "   - Systematic issue identification\n",
    "   - Quality metrics logging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@0.623] global loadsave.cpp:268 findDecoder imread_('dataset/personA/img001.jpg'): can't open/read file: check file path/integrity\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.11.0) /Users/xperience/GHA-Actions-OpenCV/_work/opencv-python/opencv-python/opencv/modules/imgproc/src/color.cpp:199: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[1;32m      3\u001b[0m img_orig \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset/personA/img001.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m, cv2\u001b[38;5;241m.\u001b[39mIMREAD_COLOR)\n\u001b[0;32m----> 4\u001b[0m img_orig \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(img_orig, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB)  \u001b[38;5;66;03m# convert BGR → RGB for plt\u001b[39;00m\n\u001b[1;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(img_orig)\n\u001b[1;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOriginal Image\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.11.0) /Users/xperience/GHA-Actions-OpenCV/_work/opencv-python/opencv-python/opencv/modules/imgproc/src/color.cpp:199: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def pick_images(folder_path):\n",
    "    \"\"\"\n",
    "    Returns a list of 15 image paths: 5 from start, 5 from middle, 5 from end.\n",
    "    If the folder has fewer than 15 images, it will return as many as possible. This is to ensure the face is cropped in \n",
    "    \"\"\"\n",
    "    # Get all subfolders\n",
    "    subfolders = [f.path for f in os.scandir(folder_path) if f.is_dir()]\n",
    "    selected_paths = []\n",
    "\n",
    "    for subfolder in subfolders:\n",
    "        # Get all image files in the subfolder\n",
    "        all_files = os.listdir(subfolder)\n",
    "        image_files = sorted([f for f in all_files if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n",
    "        \n",
    "        if len(image_files) == 0:\n",
    "            print(\"No images found in:\", subfolder)\n",
    "            continue\n",
    "        \n",
    "        n = len(image_files)\n",
    "\n",
    "        # Select images\n",
    "        if n <= 15:\n",
    "            selected_paths.extend([os.path.join(subfolder, f) for f in image_files])\n",
    "        else:\n",
    "            start_5 = image_files[:5]\n",
    "            mid_start = (n // 2) - 2  # center minus 2\n",
    "            mid_5 = image_files[mid_start:mid_start + 5]\n",
    "            end_5 = image_files[-5:]\n",
    "\n",
    "            selected_paths.extend([os.path.join(subfolder, f) for f in start_5 + mid_5 + end_5])\n",
    "\n",
    "    return selected_paths\n",
    "\n",
    "def display_images(image_paths):\n",
    "    plt.figure(figsize=(15, 5))  # Set figure size for horizontal display\n",
    "    num_images = min(len(image_paths), 15)  # Ensure we don't exceed 15 images\n",
    "    for idx, img_path in enumerate(image_paths[:num_images]):\n",
    "        # Check if file exists\n",
    "        if not os.path.exists(img_path):\n",
    "            raise FileNotFoundError(f\"Image not found at {img_path}\")\n",
    "\n",
    "        # Read and verify image loaded correctly\n",
    "        img_orig = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "        if img_orig is None:\n",
    "            raise ValueError(f\"Failed to load image at {img_path}\")\n",
    "\n",
    "        img_orig = cv2.cvtColor(img_orig, cv2.COLOR_BGR2RGB)\n",
    "        plt.subplot(3, 5, idx + 1)  # 3 rows, 5 columns\n",
    "        plt.imshow(img_orig)\n",
    "        plt.title(os.path.basename(img_path))\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "person_folders = [\n",
    "    \"/Users/ryangichuru/Documents/SSD-K/Uni/2nd year/Intro to AI/CNN/assignment-2-ryantigi254-main/data/Original Data/Anh\",\n",
    "    \"/Users/ryangichuru/Documents/SSD-K/Uni/2nd year/Intro to AI/CNN/assignment-2-ryantigi254-main/data/Original Data/Saurish\",\n",
    "    \"/Users/ryangichuru/Documents/SSD-K/Uni/2nd year/Intro to AI/CNN/assignment-2-ryantigi254-main/data/Original Data/Ryan\"\n",
    "]\n",
    "\n",
    "for person_folder in person_folders:\n",
    "    print(f\"Processing images from: {person_folder}\")\n",
    "    image_paths = pick_images(person_folder)\n",
    "    display_images(image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "SHOW_PREVIEW = False  \n",
    "\n",
    "CASCADE_PATH = os.path.join(cv2.data.haarcascades, \"haarcascade_frontalface_default.xml\")\n",
    "face_cascade = cv2.CascadeClassifier(CASCADE_PATH)\n",
    "\n",
    "# Constants for controlling face bounding box acceptance\n",
    "MIN_FACE_WIDTH = 50   # skip if the detected face's width < 50 px\n",
    "MIN_FACE_HEIGHT = 50  # skip if the detected face's height < 50 px\n",
    "\n",
    "def crop_face_if_needed(image_path, area_threshold=0.95, debug=False):\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        return None, \"Unable to read image file.\"\n",
    "\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)\n",
    "    \n",
    "    if len(faces) == 0:\n",
    "        return None, \"No face found; skipping.\"\n",
    "\n",
    "    # Pick the largest face by area\n",
    "    largest_area = 0\n",
    "    chosen_box = None\n",
    "    for (x, y, w, h) in faces:\n",
    "        area = w * h\n",
    "        if area > largest_area:\n",
    "            largest_area = area\n",
    "            chosen_box = (x, y, w, h)\n",
    "\n",
    "    x, y, w, h = chosen_box\n",
    "    face_area = w * h\n",
    "    img_area = img.shape[0] * img.shape[1]\n",
    "    coverage_ratio = face_area / float(img_area)\n",
    "\n",
    "    if debug:\n",
    "        print(f\"DEBUG: {os.path.basename(image_path)} -> coverage ratio = {coverage_ratio:.3f} (threshold={area_threshold})\")\n",
    "\n",
    "    if coverage_ratio >= area_threshold:\n",
    "        return None, f\"Face covers ~{coverage_ratio*100:.1f}% => skipping crop.\"\n",
    "    \n",
    "    # Check minimal face dimension\n",
    "    if w < MIN_FACE_WIDTH or h < MIN_FACE_HEIGHT:\n",
    "        return None, f\"Face too small (w={w}, h={h}) => skipping.\"\n",
    "\n",
    "    cropped_img = img[y:y+h, x:x+w]\n",
    "    return cropped_img, f\"Face covers ~{coverage_ratio*100:.1f}%; cropped. Face size=({w}x{h}).\"\n",
    "\n",
    "def crop_faces_recursively(input_dir, output_dir, area_threshold=0.95, debug=False):\n",
    "    for root, dirs, files in os.walk(input_dir):\n",
    "        rel_path = os.path.relpath(root, input_dir)\n",
    "        out_subdir = os.path.join(output_dir, rel_path)\n",
    "        os.makedirs(out_subdir, exist_ok=True)\n",
    "        \n",
    "        for filename in files:\n",
    "            if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                input_path = os.path.join(root, filename)\n",
    "                output_path = os.path.join(out_subdir, filename)\n",
    "\n",
    "                cropped_img, status = crop_face_if_needed(input_path, area_threshold=area_threshold, debug=debug)\n",
    "                \n",
    "                if cropped_img is not None:\n",
    "                    cv2.imwrite(output_path, cropped_img)\n",
    "                    print(f\"[Cropped] {os.path.relpath(input_path, input_dir)}: {status}\")\n",
    "\n",
    "                    if SHOW_PREVIEW:\n",
    "                        import matplotlib.pyplot as plt\n",
    "                        rgb_cropped = cv2.cvtColor(cropped_img, cv2.COLOR_BGR2RGB)\n",
    "                        plt.figure()\n",
    "                        plt.title(f\"Cropped: {filename}\")\n",
    "                        plt.imshow(rgb_cropped)\n",
    "                        plt.axis('off')\n",
    "                        plt.show()\n",
    "                else:\n",
    "                    print(f\"[Skipped] {os.path.relpath(input_path, input_dir)}: {status}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_folder = \"/Users/ryangichuru/Documents/SSD-K/Uni/2nd year/Intro to AI/CNN/assignment-2-ryantigi254-main/data/Original Data/Saurish\"\n",
    "    output_folder = \"/Users/ryangichuru/Documents/SSD-K/Uni/2nd year/Intro to AI/CNN/assignment-2-ryantigi254-main/data/Cropped Data/Saurish\"\n",
    "\n",
    "    crop_faces_recursively(input_folder, output_folder, area_threshold=0.95, debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"color: #FF0000;\">Train Test Split Process</span>\n",
    "\n",
    "The dataset is split into training, validation and test sets using a 70-15-15 ratio. This is done recursively for each user's folder while preserving the folder structure. The process involves:\n",
    "\n",
    "1. **Input**: \n",
    "   - Enhanced dataset with cropped and preprocessed face images\n",
    "   - Each user has their own folder containing their images\n",
    "\n",
    "2. **Output Structure**:\n",
    "   - train/ (70% of data)\n",
    "   - val/ (15% of data) \n",
    "   - test/ (15% of data)\n",
    "   - Each split maintains user subfolders\n",
    "\n",
    "3. **Key Features**:\n",
    "   - Random shuffling with fixed seed for reproducibility [@Web: https://scikit-learn.org/stable/common_pitfalls.html#controlling-randomness]\n",
    "   - Handles file collisions with UUID suffixes [@Web: https://docs.python.org/3/library/uuid.html]\n",
    "   - Preserves folder hierarchy [@Web: https://docs.python.org/3/library/os.html#os.makedirs]\n",
    "   - Supports both copy and move operations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import uuid\n",
    "\n",
    "def gather_images_recursively(folder_path):\n",
    "    \"\"\"\n",
    "    Recursively collects *all* .png/.jpg/.jpeg/.bmp/.webp file paths\n",
    "    under `folder_path`. Returns a list of absolute paths.\n",
    "    \"\"\"\n",
    "    all_paths = []\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for f in files:\n",
    "            if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.webp')):\n",
    "                full_path = os.path.join(root, f)\n",
    "                all_paths.append(full_path)\n",
    "    return all_paths\n",
    "\n",
    "def ensure_unique_filename(base_name, existing_files):\n",
    "    \"\"\"\n",
    "    If base_name is already in existing_files, generate a unique name by\n",
    "    appending a short UUID suffix.\n",
    "    Returns a filename guaranteed not in existing_files.\n",
    "    \"\"\"\n",
    "    if base_name not in existing_files:\n",
    "        return base_name\n",
    "    # Collision: add suffix\n",
    "    name_part, ext = os.path.splitext(base_name)\n",
    "    while True:\n",
    "        suffix = str(uuid.uuid4())[:8]  # short random suffix\n",
    "        candidate = f\"{name_part}_{suffix}{ext}\"\n",
    "        if candidate not in existing_files:\n",
    "            return candidate\n",
    "\n",
    "def split_dataset(\n",
    "    input_dir,\n",
    "    output_dir,\n",
    "    train_ratio=0.70,\n",
    "    val_ratio=0.15,\n",
    "    test_ratio=0.15,\n",
    "    copy_files=True,\n",
    "    seed=42\n",
    "):\n",
    "    \"\"\"\n",
    "    Recursively splits each user's folder into train/val/test sets,\n",
    "    keeping each image in a subfolder with the same name as the image.\n",
    "    \"\"\"\n",
    "\n",
    "    if abs((train_ratio + val_ratio + test_ratio) - 1.0) > 1e-5:\n",
    "        raise ValueError(\"train_ratio + val_ratio + test_ratio must equal 1.0\")\n",
    "\n",
    "    random.seed(seed)\n",
    "\n",
    "    # Create main subfolders: train, val, test\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    train_dir = os.path.join(output_dir, \"train\")\n",
    "    val_dir   = os.path.join(output_dir, \"val\")\n",
    "    test_dir  = os.path.join(output_dir, \"test\")\n",
    "    os.makedirs(train_dir, exist_ok=True)\n",
    "    os.makedirs(val_dir,   exist_ok=True)\n",
    "    os.makedirs(test_dir,  exist_ok=True)\n",
    "\n",
    "    # Identify user-level subfolders. E.g. \"Saurish\"\n",
    "    user_folders = [\n",
    "        d for d in os.listdir(input_dir)\n",
    "        if os.path.isdir(os.path.join(input_dir, d))\n",
    "    ]\n",
    "\n",
    "    for user_name in user_folders:\n",
    "        user_input_path = os.path.join(input_dir, user_name)\n",
    "        # Recursively gather images from sub-subfolders\n",
    "        all_img_paths = gather_images_recursively(user_input_path)\n",
    "        random.shuffle(all_img_paths)\n",
    "\n",
    "        total_files = len(all_img_paths)\n",
    "        train_count = int(total_files * 0.70)  # 70% for training\n",
    "        val_count = int(total_files * 0.15)    # 15% for validation\n",
    "        test_count = total_files - (train_count + val_count)  # Remaining for test\n",
    "\n",
    "        train_paths = all_img_paths[:train_count]\n",
    "        val_paths   = all_img_paths[train_count:train_count + val_count]\n",
    "        test_paths  = all_img_paths[train_count + val_count:]\n",
    "\n",
    "        # Create user subfolder in train/val/test\n",
    "        user_train_dir = os.path.join(train_dir, user_name)\n",
    "        user_val_dir   = os.path.join(val_dir,   user_name)\n",
    "        user_test_dir  = os.path.join(test_dir,  user_name)\n",
    "        os.makedirs(user_train_dir, exist_ok=True)\n",
    "        os.makedirs(user_val_dir,   exist_ok=True)\n",
    "        os.makedirs(user_test_dir,  exist_ok=True)\n",
    "\n",
    "        def transfer_file(src, dst_folder):\n",
    "            base_name = os.path.basename(src)\n",
    "            dst_path = os.path.join(dst_folder, base_name)\n",
    "\n",
    "            if copy_files:\n",
    "                shutil.copy2(src, dst_path)\n",
    "            else:\n",
    "                shutil.move(src, dst_path)\n",
    "\n",
    "        for p in train_paths:\n",
    "            transfer_file(p, user_train_dir)\n",
    "\n",
    "        for p in val_paths:\n",
    "            transfer_file(p, user_val_dir)\n",
    "\n",
    "        for p in test_paths:\n",
    "            transfer_file(p, user_test_dir)\n",
    "\n",
    "        print(f\"{user_name}: total={total_files} -> \"\n",
    "              f\"train={len(train_paths)}, val={len(val_paths)}, test={len(test_paths)}\")\n",
    "\n",
    "    print(\"Done splitting!\")\n",
    "    print(f\"Train folder: {train_dir}\")\n",
    "    print(f\"Val folder:   {val_dir}\")\n",
    "    print(f\"Test folder:  {test_dir}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Adjust input_folder to our dataset's \"parent\" folder:\n",
    "    input_folder  = \"/Users/ryangichuru/Documents/SSD-K/Uni/2nd year/Intro to AI/CNN/assignment-2-ryantigi254-main/data/enhanced data\"\n",
    "    output_folder = \"/Users/ryangichuru/Documents/SSD-K/Uni/2nd year/Intro to AI/CNN/assignment-2-ryantigi254-main/data/Output Data\"\n",
    "\n",
    "    split_dataset(\n",
    "        input_dir=input_folder,\n",
    "        output_dir=output_folder,\n",
    "        copy_files=True,\n",
    "        seed=42\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def organize_images_into_subfolders(base_path):\n",
    "    \"\"\"\n",
    "    Organizes images in the given path into individual subfolders.\n",
    "    Each subfolder will have the same name as the image (without extension).\n",
    "    \"\"\"\n",
    "    # Walk through all directories\n",
    "    for root, dirs, files in os.walk(base_path):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.webp')):\n",
    "                # Get full path of the image\n",
    "                file_path = os.path.join(root, file)\n",
    "                \n",
    "                # Get file name without extension\n",
    "                file_name = os.path.splitext(file)[0]\n",
    "                \n",
    "                # Create new subfolder path\n",
    "                new_folder = os.path.join(root, file_name)\n",
    "                \n",
    "                # Create subfolder if it doesn't exist\n",
    "                os.makedirs(new_folder, exist_ok=True)\n",
    "                \n",
    "                # Move image to new subfolder\n",
    "                new_file_path = os.path.join(new_folder, file)\n",
    "                if file_path != new_file_path:  # Avoid moving if already in correct place\n",
    "                    shutil.move(file_path, new_file_path)\n",
    "                    print(f\"Moved {file} to {new_folder}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    base_path = \"/Users/ryangichuru/Documents/SSD-K/Uni/2nd year/Intro to AI/CNN/assignment-2-ryantigi254-main/data/Output Data\"\n",
    "    organize_images_into_subfolders(base_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We will apply sharpening and blurring to our dataset now but this will not be used as of the moment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "apply_dip_to_dataset.py\n",
    "\n",
    "This script applies sharpening and blurring filters to facial recognition dataset images.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "SHOW_SAMPLES = True\n",
    "NUM_SAMPLES_TO_SHOW = 5\n",
    "\n",
    "def sharpen_image(bgr_img):\n",
    "    \"\"\"Applies Laplacian sharpening filter to BGR image\"\"\"\n",
    "    sharpen_kernel = np.array([[0, -1, 0],\n",
    "                              [-1, 5, -1], \n",
    "                              [0, -1, 0]], dtype=np.float32)\n",
    "    return cv2.filter2D(bgr_img, ddepth=-1, kernel=sharpen_kernel)\n",
    "\n",
    "def blur_image(bgr_img, ksize=8):  # Increased kernel size from 5 to 11\n",
    "    \"\"\"Applies Gaussian blur to BGR image\"\"\"\n",
    "    return cv2.GaussianBlur(bgr_img, (ksize, ksize), 0)\n",
    "\n",
    "def gather_images_recursively(folder_path, exts=('.png', '.jpg', '.jpeg')):\n",
    "    \"\"\"Recursively collects image paths\"\"\"\n",
    "    all_paths = []\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for f in files:\n",
    "            if f.lower().endswith(exts):\n",
    "                all_paths.append(os.path.join(root, f))\n",
    "    return all_paths\n",
    "\n",
    "def apply_dip_to_dataset(input_dir, output_dir):\n",
    "    \"\"\"Applies filters and saves results preserving folder structure\"\"\"\n",
    "    all_img_paths = gather_images_recursively(input_dir)\n",
    "    if not all_img_paths:\n",
    "        print(f\"No images found in {input_dir}\")\n",
    "        return\n",
    "\n",
    "    sample_paths = []\n",
    "    if SHOW_SAMPLES:\n",
    "        random.shuffle(all_img_paths)\n",
    "        sample_paths = all_img_paths[:NUM_SAMPLES_TO_SHOW]\n",
    "\n",
    "    for img_path in all_img_paths:\n",
    "        rel_path = os.path.relpath(img_path, input_dir)\n",
    "        bgr_img = cv2.imread(img_path)\n",
    "        if bgr_img is None:\n",
    "            print(f\"Skipping unreadable file: {img_path}\")\n",
    "            continue\n",
    "        \n",
    "        sharpened = sharpen_image(bgr_img)\n",
    "        blurred = blur_image(bgr_img, ksize=11)\n",
    "\n",
    "        # Get filename without extension\n",
    "        filename = os.path.splitext(os.path.basename(img_path))[0]\n",
    "        \n",
    "        # Create individual folders for each image\n",
    "        sharpen_folder = os.path.join(output_dir, \"sharpened\", filename)\n",
    "        blur_folder = os.path.join(output_dir, \"blurred\", filename)\n",
    "        \n",
    "        os.makedirs(sharpen_folder, exist_ok=True)\n",
    "        os.makedirs(blur_folder, exist_ok=True)\n",
    "\n",
    "        # Save images in their individual folders\n",
    "        sharpen_out = os.path.join(sharpen_folder, f\"{filename}.png\")\n",
    "        blur_out = os.path.join(blur_folder, f\"{filename}.png\")\n",
    "\n",
    "        cv2.imwrite(sharpen_out, sharpened)\n",
    "        cv2.imwrite(blur_out, blurred)\n",
    "\n",
    "    print(\"Done applying filters to dataset.\")\n",
    "    print(f\"Sharpened results in: {os.path.join(output_dir, 'sharpened')}\")\n",
    "    print(f\"Blurred results in: {os.path.join(output_dir, 'blurred')}\")\n",
    "\n",
    "    if SHOW_SAMPLES and sample_paths:\n",
    "        print(f\"Showing {len(sample_paths)} sample comparisons\")\n",
    "        for sp in sample_paths:\n",
    "            bgr = cv2.imread(sp)\n",
    "            if bgr is None:\n",
    "                continue\n",
    "\n",
    "            sharpened = sharpen_image(bgr)\n",
    "            blurred = blur_image(bgr, ksize=11)\n",
    "            \n",
    "            rgb_orig = cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)\n",
    "            rgb_sharpened = cv2.cvtColor(sharpened, cv2.COLOR_BGR2RGB)\n",
    "            rgb_blurred = cv2.cvtColor(blurred, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "            axes[0].imshow(rgb_orig)\n",
    "            axes[0].set_title(\"Original\")\n",
    "            axes[0].axis('off')\n",
    "\n",
    "            axes[1].imshow(rgb_sharpened) \n",
    "            axes[1].set_title(\"Sharpened\")\n",
    "            axes[1].axis('off')\n",
    "\n",
    "            axes[2].imshow(rgb_blurred)\n",
    "            axes[2].set_title(\"Blurred\")\n",
    "            axes[2].axis('off')\n",
    "\n",
    "            plt.suptitle(os.path.basename(sp))\n",
    "            plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_dir = \"/Users/ryangichuru/Documents/SSD-K/Uni/2nd year/Intro to AI/CNN/assignment-2-ryantigi254-main/data/Output Data\"\n",
    "    output_dir = \"/Users/ryangichuru/Documents/SSD-K/Uni/2nd year/Intro to AI/CNN/assignment-2-ryantigi254-main/data/Enhanced Output\"\n",
    "    \n",
    "    apply_dip_to_dataset(input_dir, output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"color: #FF0000;\">Data Augmentation Process</span>\n",
    "\n",
    "After applying basic image processing techniques (sharpening and blurring), we implement additional data augmentation separately from the main transfer learning pipeline. While this creates a longer workflow, it provides several key benefits:\n",
    "\n",
    "1. **Better Process Understanding**: \n",
    "   - Separating augmentation helps us understand exactly how the data is being transformed\n",
    "   - Allows visual inspection of augmented images before training\n",
    "   - Provides more control over the augmentation parameters\n",
    "\n",
    "2. **Augmentation Techniques Applied**:\n",
    "   - Rotation (±10 degrees)\n",
    "   - Width/height shifts (±10%)\n",
    "   - Zoom variations (±10%)\n",
    "   - Brightness adjustments (±10%)\n",
    "   - Horizontal flips\n",
    "   - Nearest neighbor fill mode\n",
    "\n",
    "3. **Control Benefits**:\n",
    "   - Can verify quality of augmented images\n",
    "   - Ability to adjust parameters based on visual results\n",
    "   - Ensures consistent augmentation across training runs\n",
    "   - Maintains data integrity through the process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "augment_dataset.py\n",
    "Ensures exactly 3x augmented images per person within train/val/test splits.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def augment_person_folder(datagen, person_dir, output_dir, multiplier=3):\n",
    "    \"\"\"\n",
    "    Augments images for a single person's folder to ensure exactly multiplier times images.\n",
    "    Saves directly in subfolders under the person's directory.\n",
    "    \"\"\"\n",
    "    person_name = os.path.basename(person_dir)\n",
    "    person_output_dir = os.path.join(output_dir, person_name)\n",
    "    os.makedirs(person_output_dir, exist_ok=True)\n",
    "\n",
    "    # Count original images\n",
    "    original_images = []\n",
    "    for root, _, files in os.walk(person_dir):\n",
    "        for f in files:\n",
    "            if f.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                original_images.append(os.path.join(root, f))\n",
    "    \n",
    "    n_original = len(original_images)\n",
    "    n_to_generate = n_original * multiplier\n",
    "\n",
    "    print(f\"\\nProcessing {person_name}:\")\n",
    "    print(f\"Original images: {n_original}\")\n",
    "    print(f\"To generate: {n_to_generate}\")\n",
    "\n",
    "    if n_original > 0:\n",
    "        # Setup generator for this person\n",
    "        person_generator = datagen.flow_from_directory(\n",
    "            directory=os.path.dirname(person_dir),\n",
    "            classes=[person_name],\n",
    "            target_size=(180, 180),\n",
    "            batch_size=1,\n",
    "            shuffle=True,\n",
    "            save_to_dir=None\n",
    "        )\n",
    "\n",
    "        # Generate augmented images\n",
    "        for i in range(n_to_generate):\n",
    "            batch = next(person_generator)\n",
    "            img = batch[0][0]\n",
    "            \n",
    "            # Create sequential numbered folder directly under person's directory\n",
    "            folder_name = f\"{i+1}\"  # Just the number\n",
    "            img_folder = os.path.join(person_output_dir, folder_name)\n",
    "            os.makedirs(img_folder, exist_ok=True)\n",
    "            \n",
    "            # Save image with same name as folder\n",
    "            img_path = os.path.join(img_folder, f\"{folder_name}.jpg\")\n",
    "            tf.keras.preprocessing.image.save_img(img_path, img)\n",
    "            \n",
    "            if (i + 1) % 10 == 0:\n",
    "                print(f\"Generated {i + 1}/{n_to_generate} augmented images\")\n",
    "\n",
    "    final_count = sum(1 for _ in os.walk(person_output_dir))\n",
    "    print(f\"Final folder count for {person_name}: {final_count}\")\n",
    "    return final_count\n",
    "\n",
    "def main():\n",
    "    # Paths\n",
    "    base_input_dir = \"/Users/ryangichuru/Documents/SSD-K/Uni/2nd year/Intro to AI/CNN/assignment-2-ryantigi254-main/data/Output Data\"\n",
    "    base_output_dir = \"/Users/ryangichuru/Documents/SSD-K/Uni/2nd year/Intro to AI/CNN/assignment-2-ryantigi254-main/data/Enhanced Output\"\n",
    "\n",
    "    # Clear output dir if it exists\n",
    "    if os.path.exists(base_output_dir):\n",
    "        shutil.rmtree(base_output_dir)\n",
    "    os.makedirs(base_output_dir)\n",
    "\n",
    "    # Augmentation settings optimized for facial recognition\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=10,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        zoom_range=0.1,\n",
    "        brightness_range=[0.9, 1.1],\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "\n",
    "    # Process each split (train/val/test)\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        split_input_dir = os.path.join(base_input_dir, split)\n",
    "        split_output_dir = os.path.join(base_output_dir, split)\n",
    "        os.makedirs(split_output_dir, exist_ok=True)\n",
    "        \n",
    "        print(f\"\\nProcessing {split} split:\")\n",
    "        total_split_images = 0\n",
    "        \n",
    "        # Process each person within the split\n",
    "        for person_name in os.listdir(split_input_dir):\n",
    "            person_dir = os.path.join(split_input_dir, person_name)\n",
    "            if os.path.isdir(person_dir):\n",
    "                count = augment_person_folder(\n",
    "                    datagen, \n",
    "                    person_dir, \n",
    "                    split_output_dir, \n",
    "                    multiplier=3\n",
    "                )\n",
    "                total_split_images += count\n",
    "        \n",
    "        print(f\"Total {split} folders after augmentation: {total_split_images}\")\n",
    "\n",
    "    print(\"\\nAugmentation complete!\")\n",
    "    print(f\"Output directory: {base_output_dir}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "augment_dataset.py\n",
    "Ensures exactly 3x augmented images per person within train/val/test splits.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def augment_person_folder(datagen, person_dir, output_dir, multiplier=3):\n",
    "    \"\"\"\n",
    "    Augments images for a single person's folder to ensure exactly multiplier times images.\n",
    "    Only saves the augmented versions.\n",
    "    \"\"\"\n",
    "    person_name = os.path.basename(person_dir)\n",
    "    person_output_dir = os.path.join(output_dir, person_name)\n",
    "    os.makedirs(person_output_dir, exist_ok=True)\n",
    "\n",
    "    # Count original images\n",
    "    original_images = []\n",
    "    for root, _, files in os.walk(person_dir):\n",
    "        for f in files:\n",
    "            if f.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                original_images.append(os.path.join(root, f))\n",
    "    \n",
    "    n_original = len(original_images)\n",
    "    n_to_generate = n_original * multiplier  # Generate multiplier times the original count\n",
    "\n",
    "    print(f\"\\nProcessing {person_name}:\")\n",
    "    print(f\"Original images: {n_original}\")\n",
    "    print(f\"To generate: {n_to_generate}\")\n",
    "\n",
    "    if n_original > 0:\n",
    "        # Setup generator for this person\n",
    "        person_generator = datagen.flow_from_directory(\n",
    "            directory=os.path.dirname(person_dir),\n",
    "            classes=[person_name],\n",
    "            target_size=(180, 180),\n",
    "            batch_size=1,\n",
    "            shuffle=True,\n",
    "            save_to_dir=None\n",
    "        )\n",
    "\n",
    "        # Generate augmented images\n",
    "        for i in range(n_to_generate):\n",
    "            batch = next(person_generator)\n",
    "            img = batch[0][0]\n",
    "            \n",
    "            # Create unique folder and save image\n",
    "            aug_name = f\"aug_{person_name}_{i+1}\"\n",
    "            aug_folder = os.path.join(person_output_dir, aug_name)\n",
    "            os.makedirs(aug_folder, exist_ok=True)\n",
    "            \n",
    "            # Save the augmented image\n",
    "            img_path = os.path.join(aug_folder, f\"{aug_name}.jpg\")\n",
    "            tf.keras.preprocessing.image.save_img(img_path, img)\n",
    "            \n",
    "            if (i + 1) % 10 == 0:\n",
    "                print(f\"Generated {i + 1}/{n_to_generate} augmented images\")\n",
    "\n",
    "    final_count = sum(1 for _ in os.walk(person_output_dir))\n",
    "    print(f\"Final folder count for {person_name}: {final_count}\")\n",
    "    return final_count\n",
    "\n",
    "def main():\n",
    "    # Paths\n",
    "    base_input_dir = \"/Users/ryangichuru/Documents/SSD-K/Uni/2nd year/Intro to AI/CNN/assignment-2-ryantigi254-main/data/Output Data\"\n",
    "    base_output_dir = \"/Users/ryangichuru/Documents/SSD-K/Uni/2nd year/Intro to AI/CNN/assignment-2-ryantigi254-main/data/Augmented Output\"\n",
    "\n",
    "    # Clear output dir if it exists\n",
    "    if os.path.exists(base_output_dir):\n",
    "        shutil.rmtree(base_output_dir)\n",
    "    os.makedirs(base_output_dir)\n",
    "\n",
    "    # Augmentation settings optimized for facial recognition\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=10,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        zoom_range=0.1,\n",
    "        brightness_range=[0.9, 1.1],\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "\n",
    "    # Process each split (train/val/test)\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        split_input_dir = os.path.join(base_input_dir, split)\n",
    "        split_output_dir = os.path.join(base_output_dir, split)\n",
    "        os.makedirs(split_output_dir, exist_ok=True)\n",
    "        \n",
    "        print(f\"\\nProcessing {split} split:\")\n",
    "        total_split_images = 0\n",
    "        \n",
    "        # Process each person within the split\n",
    "        for person_name in os.listdir(split_input_dir):\n",
    "            person_dir = os.path.join(split_input_dir, person_name)\n",
    "            if os.path.isdir(person_dir):\n",
    "                count = augment_person_folder(\n",
    "                    datagen, \n",
    "                    person_dir, \n",
    "                    split_output_dir, \n",
    "                    multiplier=3\n",
    "                )\n",
    "                total_split_images += count\n",
    "        \n",
    "        print(f\"Total {split} folders after augmentation: {total_split_images}\")\n",
    "\n",
    "    print(\"\\nAugmentation complete!\")\n",
    "    print(f\"Output directory: {base_output_dir}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"color: #FF0000;\">Step 2 Data Augmentation Process</span>\n",
    "\n",
    "After applying basic image processing techniques (sharpening and blurring), we implement additional data augmentation separately from the main transfer learning pipeline. While this creates a longer workflow, it provides several key benefits:\n",
    "\n",
    "1. **Better Process Understanding**: \n",
    "   - Separating augmentation helps us understand exactly how the data is being transformed\n",
    "   - Allows visual inspection of augmented images before training\n",
    "   - Provides more control over the augmentation parameters\n",
    "\n",
    "2. **Augmentation Techniques Applied**:\n",
    "   - Rotation (±10 degrees)\n",
    "   - Width/height shifts (±10%)\n",
    "   - Zoom variations (±10%)\n",
    "   - Brightness adjustments (±10%)\n",
    "   - Horizontal flips\n",
    "   - Nearest neighbor fill mode\n",
    "\n",
    "3. **Control Benefits**:\n",
    "   - Can verify quality of augmented images\n",
    "   - Ability to adjust parameters based on visual results\n",
    "   - Ensures consistent augmentation across training runs\n",
    "   - Maintains data integrity through the process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "augment_dataset.py\n",
    "Ensures exactly 3x augmented images per person within train/val/test splits.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "def augment_person_folder(datagen, person_dir, output_dir, multiplier=3):\n",
    "    \"\"\"\n",
    "    Augments images for a single person's folder to ensure exactly multiplier times images.\n",
    "    Only saves the augmented versions.\n",
    "    \"\"\"\n",
    "    person_name = os.path.basename(person_dir)\n",
    "    person_output_dir = os.path.join(output_dir, person_name)\n",
    "    os.makedirs(person_output_dir, exist_ok=True)\n",
    "\n",
    "    # Count original images\n",
    "    original_images = []\n",
    "    for root, _, files in os.walk(person_dir):\n",
    "        for f in files:\n",
    "            if f.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                original_images.append(os.path.join(root, f))\n",
    "    \n",
    "    n_original = len(original_images)\n",
    "    n_to_generate = n_original * multiplier  # Generate multiplier times the original count\n",
    "\n",
    "    print(f\"\\nProcessing {person_name}:\")\n",
    "    print(f\"Original images: {n_original}\")\n",
    "    print(f\"To generate: {n_to_generate}\")\n",
    "\n",
    "    if n_original > 0:\n",
    "        # Setup generator for this person\n",
    "        person_generator = datagen.flow_from_directory(\n",
    "            directory=os.path.dirname(person_dir),\n",
    "            classes=[person_name],\n",
    "            target_size=(180, 180),\n",
    "            batch_size=1,\n",
    "            shuffle=True,\n",
    "            save_to_dir=None\n",
    "        )\n",
    "\n",
    "        # Generate augmented images\n",
    "        for i in range(n_to_generate):\n",
    "            batch = next(person_generator)\n",
    "            img = batch[0][0]\n",
    "            \n",
    "            # Create unique folder and save image\n",
    "            aug_name = f\"aug_{person_name}_{i+1}\"\n",
    "            aug_folder = os.path.join(person_output_dir, aug_name)\n",
    "            os.makedirs(aug_folder, exist_ok=True)\n",
    "            \n",
    "            # Save the augmented image\n",
    "            img_path = os.path.join(aug_folder, f\"{aug_name}.jpg\")\n",
    "            tf.keras.preprocessing.image.save_img(img_path, img)\n",
    "            \n",
    "            if (i + 1) % 10 == 0:\n",
    "                print(f\"Generated {i + 1}/{n_to_generate} augmented images\")\n",
    "\n",
    "    final_count = sum(1 for _ in os.walk(person_output_dir))\n",
    "    print(f\"Final folder count for {person_name}: {final_count}\")\n",
    "    return final_count\n",
    "\n",
    "\n",
    "def offline_augment_dataset(\n",
    "    base_input_dir,\n",
    "    base_output_dir,\n",
    "    multiplier=3,\n",
    "    shear_range=10,\n",
    "    channel_shift_range=50,\n",
    "    width_shift_range=0.15,\n",
    "    height_shift_range=0.15,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    "):\n",
    "    \"\"\"\n",
    "    For train/val/test in `base_input_dir`, create a mirrored structure in\n",
    "    `base_output_dir`, and produce new images via the given transformations.\n",
    "    \"\"\"\n",
    "    abs_in = os.path.abspath(base_input_dir)\n",
    "    abs_out = os.path.abspath(base_output_dir)\n",
    "    if abs_out.startswith(abs_in):\n",
    "        raise ValueError(\n",
    "            f\"Output folder '{base_output_dir}' is inside/same as input '{base_input_dir}'. \"\n",
    "            \"Must be distinct to avoid overwriting or scanning itself.\"\n",
    "        )\n",
    "\n",
    "    # Recreate output\n",
    "    if os.path.exists(base_output_dir):\n",
    "        shutil.rmtree(base_output_dir)\n",
    "    os.makedirs(base_output_dir)\n",
    "\n",
    "    datagen = ImageDataGenerator(\n",
    "        shear_range=shear_range,\n",
    "        channel_shift_range=channel_shift_range,\n",
    "        width_shift_range=width_shift_range,\n",
    "        height_shift_range=height_shift_range,\n",
    "        zoom_range=zoom_range,\n",
    "        horizontal_flip=horizontal_flip,\n",
    "        fill_mode=fill_mode\n",
    "    )\n",
    "\n",
    "    # Creating directories for train/val/test\n",
    "    for subset_name in [\"train\", \"val\", \"test\"]:\n",
    "        subset_in = os.path.join(base_input_dir, subset_name)\n",
    "        if not os.path.isdir(subset_in):\n",
    "            print(f\"Warning: No {subset_name} folder in {base_input_dir}, skipping.\")\n",
    "            continue\n",
    "\n",
    "        subset_out = os.path.join(base_output_dir, subset_name)\n",
    "        os.makedirs(subset_out, exist_ok=True)\n",
    "\n",
    "        # For each class subfolder\n",
    "        for person_name in os.listdir(subset_in):\n",
    "            person_dir = os.path.join(subset_in, person_name)\n",
    "            if os.path.isdir(person_dir):\n",
    "                out_dir = os.path.join(subset_out, person_name)\n",
    "                os.makedirs(out_dir, exist_ok=True)\n",
    "                augment_person_folder(datagen, person_dir, out_dir, multiplier=multiplier)\n",
    "\n",
    "    print(f\"\\nOffline augmentation complete for '{base_input_dir}'\")\n",
    "    print(f\"Augmented data placed in '{base_output_dir}'\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Paths\n",
    "    base_input_dir = \"/Users/ryangichuru/Documents/SSD-K/Uni/2nd year/Intro to AI/CNN/assignment-2-ryantigi254-main/data/Output Data\"\n",
    "    base_output_dir = \"/Users/ryangichuru/Documents/SSD-K/Uni/2nd year/Intro to AI/CNN/assignment-2-ryantigi254-main/data/Augmented Output2\"\n",
    "\n",
    "    # Clear output dir if it exists\n",
    "    if os.path.exists(base_output_dir):\n",
    "        shutil.rmtree(base_output_dir)\n",
    "    os.makedirs(base_output_dir)\n",
    "\n",
    "    # Augmentation settings optimized for facial recognition\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=10,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        zoom_range=0.1,\n",
    "        brightness_range=[0.9, 1.1],\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "\n",
    "    # Process each split (train/val/test)\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        split_input_dir = os.path.join(base_input_dir, split)\n",
    "        split_output_dir = os.path.join(base_output_dir, split)\n",
    "        os.makedirs(split_output_dir, exist_ok=True)\n",
    "        \n",
    "        print(f\"\\nProcessing {split} split:\")\n",
    "        total_split_images = 0\n",
    "        \n",
    "        # Process each person within the split\n",
    "        for person_name in os.listdir(split_input_dir):\n",
    "            person_dir = os.path.join(split_input_dir, person_name)\n",
    "            if os.path.isdir(person_dir):\n",
    "                count = augment_person_folder(\n",
    "                    datagen, \n",
    "                    person_dir, \n",
    "                    split_output_dir, \n",
    "                    multiplier=3\n",
    "                )\n",
    "                total_split_images += count\n",
    "        \n",
    "        print(f\"Total {split} folders after augmentation: {total_split_images}\")\n",
    "\n",
    "    print(\"\\nAugmentation complete!\")\n",
    "    print(f\"Output directory: {base_output_dir}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"color: #FF0000;\">Dataset Rebalancing Process</span>\n",
    "\n",
    "The goal was to ensure equal representation of each subject in our facial recognition dataset to prevent model bias. Initial analysis revealed uneven distribution of images across subjects, which could lead to the model overfitting to subjects with more training data while underperforming on those with fewer samples. This rebalancing process aims to create a more equitable dataset by:\n",
    "\n",
    "1. **Counting Images**: Systematically count images for each subject across train/val/test splits\n",
    "2. **Finding Minimum**: Determine minimum number of images per subject in each split\n",
    "3. **Random Selection**: Randomly select equal numbers of images per subject\n",
    "4. **Copying Data**: Create new balanced dataset structure with selected images\n",
    "\n",
    "##### <span style=\"color: #1E90FF;\">Key Functions</span>\n",
    "\n",
    "1. **count_face_images()**: Traverses dataset structure counting images per subject\n",
    "2. **rebalance_dataset()**: Ensures equal representation by copying minimum number of images\n",
    "3. **main()**: Orchestrates rebalancing across multiple dataset versions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "def count_face_images(dataset_path):\n",
    "    \"\"\"\n",
    "    Count images with faces for each person in each split.\n",
    "    Returns a nested dictionary of counts and image paths.\n",
    "    \"\"\"\n",
    "    data = defaultdict(lambda: defaultdict(list))\n",
    "    \n",
    "    for split in ['train', 'val', 'test']:\n",
    "        split_path = os.path.join(dataset_path, split)\n",
    "        if not os.path.exists(split_path):\n",
    "            continue\n",
    "            \n",
    "        for person in os.listdir(split_path):\n",
    "            person_path = os.path.join(split_path, person)\n",
    "            if not os.path.isdir(person_path):\n",
    "                continue\n",
    "                \n",
    "            # Get all image folders\n",
    "            for img_folder in os.listdir(person_path):\n",
    "                folder_path = os.path.join(person_path, img_folder)\n",
    "                if os.path.isdir(folder_path):\n",
    "                    # Each folder should contain exactly one image\n",
    "                    images = [f for f in os.listdir(folder_path) \n",
    "                            if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "                    if images:\n",
    "                        data[split][person].append(folder_path)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def rebalance_dataset(input_path, output_path):\n",
    "    \"\"\"\n",
    "    Rebalance dataset ensuring equal numbers of images per person per split.\n",
    "    \"\"\"\n",
    "    # Get current distribution\n",
    "    data = count_face_images(input_path)\n",
    "    \n",
    "    # Find minimum counts for each split\n",
    "    min_counts = {}\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        if split in data:\n",
    "            counts = [len(data[split][person]) for person in data[split]]\n",
    "            min_counts[split] = min(counts) if counts else 0\n",
    "    \n",
    "    print(\"\\nMinimum counts per split:\")\n",
    "    for split, count in min_counts.items():\n",
    "        print(f\"{split}: {count}\")\n",
    "    \n",
    "    # Create output directory structure\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    \n",
    "    # Rebalance each split\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        if split not in min_counts or min_counts[split] == 0:\n",
    "            continue\n",
    "            \n",
    "        target_count = min_counts[split]\n",
    "        split_output = os.path.join(output_path, split)\n",
    "        os.makedirs(split_output, exist_ok=True)\n",
    "        \n",
    "        print(f\"\\nRebalancing {split} split to {target_count} images per person\")\n",
    "        \n",
    "        for person in data[split]:\n",
    "            person_images = data[split][person]\n",
    "            random.shuffle(person_images)  # Randomize selection\n",
    "            selected_images = person_images[:target_count]\n",
    "            \n",
    "            # Create person directory in output\n",
    "            person_output = os.path.join(split_output, person)\n",
    "            os.makedirs(person_output, exist_ok=True)\n",
    "            \n",
    "            print(f\"  {person}: {len(selected_images)} images\")\n",
    "            \n",
    "            # Copy selected images\n",
    "            for idx, img_folder in enumerate(selected_images, 1):\n",
    "                # Create new folder name\n",
    "                new_folder_name = f\"{person}_{idx}\"\n",
    "                new_folder_path = os.path.join(person_output, new_folder_name)\n",
    "                os.makedirs(new_folder_path, exist_ok=True)\n",
    "                \n",
    "                # Find and copy the image\n",
    "                for file in os.listdir(img_folder):\n",
    "                    if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                        src = os.path.join(img_folder, file)\n",
    "                        dst = os.path.join(new_folder_path, f\"{new_folder_name}.jpg\")\n",
    "                        shutil.copy2(src, dst)\n",
    "                        break\n",
    "\n",
    "def main():\n",
    "    base_dir = \"/Users/ryangichuru/Documents/SSD-K/Uni/2nd year/Intro to AI/CNN/assignment-2-ryantigi254-main/data\"\n",
    "    \n",
    "    # Process each dataset\n",
    "    datasets = ['Augmented Output', 'Output Data', 'Augmented Output2']\n",
    "    \n",
    "    for dataset in datasets:\n",
    "        input_path = os.path.join(base_dir, 'Rebalanced Output', dataset)\n",
    "        output_path = os.path.join(base_dir, 'Final Balanced Output', dataset)\n",
    "        \n",
    "        if os.path.exists(input_path):\n",
    "            print(f\"\\nProcessing dataset: {dataset}\")\n",
    "            rebalance_dataset(input_path, output_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    random.seed(42)  # For reproducibility\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Face Detection Pipeline\n",
    "\n",
    "##### <span style=\"color: #FF0000;\">Note</span>\n",
    "This is our second implementation aimed at improving face-to-image ratio after our initial attempts produced suboptimal results. The enhanced pipeline includes more aggressive cropping and better handling of distant faces.\n",
    "\n",
    "### Overview\n",
    "This pipeline uses **MTCNN** (Multi-task Cascaded Convolutional Networks) to detect and process faces in our dataset. It standardizes face images through consistent detection, cropping, and resizing.\n",
    "\n",
    "### Key Features\n",
    "1. **Robust Face Detection**  \n",
    "   - Uses MTCNN's deep learning architecture\n",
    "   - Filters low confidence detections (<0.9 threshold)\n",
    "\n",
    "2. **Distant Face Handling**  \n",
    "   - Identifies faces with small face-to-image ratio (<0.1)\n",
    "   - Attempts zoom-in via margin cropping\n",
    "   - Logs paths to 'far_faces.txt' for review\n",
    "\n",
    "3. **Standardization**  \n",
    "   - Crops to detected face region\n",
    "   - Resizes all faces to 180x180px\n",
    "   - Organizes into class-specific folders\n",
    "\n",
    "4. **Quality Control**  \n",
    "   - Tracks problematic images\n",
    "   - Enables manual review of edge cases\n",
    "   - Maintains consistent output quality\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install mtcnn opencv-python pillow numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from mtcnn import MTCNN\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def process_dataset(input_dir, output_dir):\n",
    "    detector = MTCNN()\n",
    "    far_faces = []\n",
    "    far_face_images = []\n",
    "    \n",
    "    # Create output directories for each split\n",
    "    splits = ['train', 'test', 'val']\n",
    "    classes = ['Anh', 'Ryan', 'Saurish']\n",
    "    \n",
    "    for split in splits:\n",
    "        for class_name in classes:\n",
    "            os.makedirs(os.path.join(output_dir, split, class_name), exist_ok=True)\n",
    "    \n",
    "    # Process each split\n",
    "    for split in splits:\n",
    "        split_path = os.path.join(input_dir, split)\n",
    "        \n",
    "        for class_name in classes:\n",
    "            class_path = os.path.join(split_path, class_name)\n",
    "            if not os.path.isdir(class_path):\n",
    "                continue\n",
    "                \n",
    "            # Process each image folder\n",
    "            for img_folder in os.listdir(class_path):\n",
    "                folder_path = os.path.join(class_path, img_folder)\n",
    "                if not os.path.isdir(folder_path):\n",
    "                    continue\n",
    "                    \n",
    "                # Get the image from the folder\n",
    "                img_files = [f for f in os.listdir(folder_path) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "                if not img_files:\n",
    "                    continue\n",
    "                    \n",
    "                img_path = os.path.join(folder_path, img_files[0])\n",
    "                img = cv2.imread(img_path)\n",
    "                if img is None:\n",
    "                    continue\n",
    "                    \n",
    "                rgb_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                faces = detector.detect_faces(rgb_img)\n",
    "                \n",
    "                if not faces:\n",
    "                    print(f\"No face detected: {img_path}\")\n",
    "                    continue\n",
    "                    \n",
    "                for face in faces:\n",
    "                    confidence = face['confidence']\n",
    "                    if confidence < 0.9:\n",
    "                        continue\n",
    "                        \n",
    "                    x, y, w, h = face['box']\n",
    "                    face_area = w * h\n",
    "                    img_area = img.shape[0] * img.shape[1]\n",
    "                    face_ratio = face_area / img_area\n",
    "                    \n",
    "                    # Check if face is too small/far\n",
    "                    if face_ratio < 0.1:\n",
    "                        far_faces.append(img_path)\n",
    "                        far_face_images.append(rgb_img)\n",
    "                        # Attempt to zoom\n",
    "                        margin = int(max(w, h) * 0.5)\n",
    "                        x1 = max(0, x - margin)\n",
    "                        y1 = max(0, y - margin)\n",
    "                        x2 = min(img.shape[1], x + w + margin)\n",
    "                        y2 = min(img.shape[0], y + h + margin)\n",
    "                        face_img = img[y1:y2, x1:x2]\n",
    "                    else:\n",
    "                        face_img = img[y:y+h, x:x+w]\n",
    "                    \n",
    "                    # Resize to standard size\n",
    "                    face_img = cv2.resize(face_img, (180, 180))\n",
    "                    \n",
    "                    # Save processed image\n",
    "                    output_path = os.path.join(output_dir, split, class_name, img_folder + '.jpg')\n",
    "                    cv2.imwrite(output_path, face_img)\n",
    "    \n",
    "    # Save list of far faces\n",
    "    with open('far_faces.txt', 'w') as f:\n",
    "        f.write('\\n'.join(far_faces))\n",
    "    \n",
    "    # Display all distant faces\n",
    "    if far_face_images:\n",
    "        n_images = len(far_face_images)\n",
    "        n_cols = 5\n",
    "        n_rows = (n_images + n_cols - 1) // n_cols\n",
    "        \n",
    "        plt.figure(figsize=(20, 4*n_rows))\n",
    "        for i, img in enumerate(far_face_images):\n",
    "            plt.subplot(n_rows, n_cols, i+1)\n",
    "            plt.imshow(img)\n",
    "            plt.axis('off')\n",
    "            plt.title(f'Distant Face {i+1}')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    return len(far_faces)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Original data path\n",
    "    original_data_dir = \"/Users/ryangichuru/Documents/SSD-K/Uni/2nd year/Intro to AI/CNN/assignment-2-ryantigi254-main/data/Final Balanced Output/Output Data\"\n",
    "    \n",
    "    # Already augmented path\n",
    "    augmented1_dir = \"/Users/ryangichuru/Documents/SSD-K/Uni/2nd year/Intro to AI/CNN/assignment-2-ryantigi254-main/data/Final Balanced Output/Augmented Output\"\n",
    "    \n",
    "    # New augmented path\n",
    "    augmented2_dir = \"/Users/ryangichuru/Documents/SSD-K/Uni/2nd year/Intro to AI/CNN/assignment-2-ryantigi254-main/data/Final Balanced Output/Augmented Output2\"\n",
    "    \n",
    "    output_dir = \"/Users/ryangichuru/Documents/SSD-K/Uni/2nd year/Intro to AI/CNN/assignment-2-ryantigi254-main/data/Processed_Faces\"\n",
    "    \n",
    "    # Process each dataset\n",
    "    for input_dir in [original_data_dir, augmented1_dir, augmented2_dir]:\n",
    "        print(f\"\\nProcessing dataset: {os.path.basename(input_dir)}\")\n",
    "        far_faces = process_dataset(input_dir, output_dir)\n",
    "        print(f\"Found {far_faces} images with distant faces\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Detection and Smart Zoom Processing\n",
    "\n",
    "### Overview\n",
    "This script implements face detection and intelligent zooming for preprocessing our face recognition dataset. Instead of using raw images, we leverage **MTCNN** (Multi-task Cascaded Convolutional Networks) to detect and extract high-quality face regions.\n",
    "\n",
    "### Why Smart Zooming?\n",
    "1. **Quality Control**  \n",
    "   We enforce strict face-to-image ratio bounds (0.15-0.6) to ensure consistent, well-framed faces.\n",
    "2. **Intelligent Cropping**  \n",
    "   The zoom algorithm maintains face quality while removing excess background.\n",
    "3. **Robust Detection**  \n",
    "   High confidence threshold (0.95) ensures we only keep clear, unambiguous face detections.\n",
    "\n",
    "### Key Parameters\n",
    "- **min_face_ratio**: 0.15 (minimum face-to-image ratio)\n",
    "- **max_face_ratio**: 0.6 (maximum face-to-image ratio)\n",
    "- **confidence_threshold**: 0.95 (minimum detection confidence)\n",
    "- **zoom_margin**: 0.7 (extra margin when zooming)\n",
    "\n",
    "### Filtering Criteria\n",
    "Images are skipped if they:\n",
    "- Have no detectable faces\n",
    "- Have low confidence detections\n",
    "- Lose face detection after zoom\n",
    "- Have poor face ratios post-zoom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from mtcnn import MTCNN\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "def process_and_zoom_faces(input_dir, output_dir, min_face_ratio=0.15, max_face_ratio=0.6):\n",
    "   detector = MTCNN()\n",
    "   \n",
    "   # Create output structure\n",
    "   for root, dirs, _ in os.walk(input_dir):\n",
    "       rel_path = os.path.relpath(root, input_dir)\n",
    "       out_path = os.path.join(output_dir, rel_path)\n",
    "       os.makedirs(out_path, exist_ok=True)\n",
    "\n",
    "   skipped_images = []\n",
    "   \n",
    "   for root, _, files in os.walk(input_dir):\n",
    "       for img_name in files:\n",
    "           if not img_name.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "               continue\n",
    "               \n",
    "           rel_path = os.path.relpath(root, input_dir)\n",
    "           input_path = os.path.join(root, img_name)\n",
    "           output_path = os.path.join(output_dir, rel_path, img_name)\n",
    "           \n",
    "           img = cv2.imread(input_path)\n",
    "           if img is None:\n",
    "               continue\n",
    "               \n",
    "           rgb_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "           faces = detector.detect_faces(rgb_img)\n",
    "           \n",
    "           if not faces:\n",
    "               skipped_images.append(f\"No face: {input_path}\")\n",
    "               continue\n",
    "           \n",
    "           # Get largest face\n",
    "           face = max(faces, key=lambda x: x['box'][2] * x['box'][3])\n",
    "           if face['confidence'] < 0.95:\n",
    "               skipped_images.append(f\"Low confidence: {input_path}\")\n",
    "               continue\n",
    "           \n",
    "           x, y, w, h = face['box']\n",
    "           face_area = w * h\n",
    "           img_area = img.shape[0] * img.shape[1]\n",
    "           face_ratio = face_area / img_area\n",
    "           \n",
    "           # Calculate zoom if needed\n",
    "           if face_ratio < min_face_ratio:\n",
    "               margin = int(max(w, h) * 0.7)\n",
    "               x1 = max(0, x - margin)\n",
    "               y1 = max(0, y - margin)\n",
    "               x2 = min(img.shape[1], x + w + margin)\n",
    "               y2 = min(img.shape[0], y + h + margin)\n",
    "               cropped = img[y1:y2, x1:x2]\n",
    "               \n",
    "               # Verify face ratio after zoom\n",
    "               faces_after = detector.detect_faces(cv2.cvtColor(cropped, cv2.COLOR_BGR2RGB))\n",
    "               if not faces_after:\n",
    "                   skipped_images.append(f\"Lost face after zoom: {input_path}\")\n",
    "                   continue\n",
    "                   \n",
    "               face_after = max(faces_after, key=lambda x: x['box'][2] * x['box'][3])\n",
    "               new_ratio = (face_after['box'][2] * face_after['box'][3]) / (cropped.shape[0] * cropped.shape[1])\n",
    "               \n",
    "               if min_face_ratio <= new_ratio <= max_face_ratio:\n",
    "                   cv2.imwrite(output_path, cropped)\n",
    "               else:\n",
    "                   skipped_images.append(f\"Bad ratio after zoom: {input_path}\")\n",
    "           else:\n",
    "               cv2.imwrite(output_path, img)\n",
    "   \n",
    "   with open('skipped_images.txt', 'w') as f:\n",
    "       f.write('\\n'.join(skipped_images))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "   original_data_dir = \"/Users/ryangichuru/Documents/SSD-K/Uni/2nd year/Intro to AI/CNN/assignment-2-ryantigi254-main/data/Final Balanced Output/Output Data\"\n",
    "   augmented1_dir = \"/Users/ryangichuru/Documents/SSD-K/Uni/2nd year/Intro to AI/CNN/assignment-2-ryantigi254-main/data/Final Balanced Output/Augmented Output\"\n",
    "   augmented2_dir = \"/Users/ryangichuru/Documents/SSD-K/Uni/2nd year/Intro to AI/CNN/assignment-2-ryantigi254-main/data/Final Balanced Output/Augmented Output2\"\n",
    "   output_dir = \"/Users/ryangichuru/Documents/SSD-K/Uni/2nd year/Intro to AI/CNN/assignment-2-ryantigi254-main/data/Processed_Faces\"\n",
    "   \n",
    "   for input_dir in [original_data_dir, augmented1_dir, augmented2_dir]:\n",
    "       print(f\"\\nProcessing dataset: {os.path.basename(input_dir)}\")\n",
    "       process_and_zoom_faces(input_dir, output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"color: #FF0000;\">Reprocessing Skipped Images</span>\n",
    "\n",
    "After initial face detection and processing, we reprocess any skipped images to maximize usable data. This separate reprocessing step provides several benefits:\n",
    "\n",
    "1. **Multiple Processing Attempts**:\n",
    "   - Gives images multiple chances to pass face detection\n",
    "   - Helps handle temporary detection failures\n",
    "   - Maximizes dataset completeness\n",
    "\n",
    "2. **Adjusted Parameters**:\n",
    "   - Multiple detection attempts with varying confidence thresholds\n",
    "   - Refined face ratio calculations\n",
    "   - Additional margin adjustments for zooming\n",
    "\n",
    "3. **Quality Control**:\n",
    "   - Tracks persistently problematic images\n",
    "   - Maintains high quality standards\n",
    "   - Ensures consistent face detection across dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import MTCNN detector\n",
    "from mtcnn import MTCNN\n",
    "detector = MTCNN()\n",
    "\n",
    "# Read skipped images file\n",
    "with open('skipped_images.txt', 'r') as f:\n",
    "    skipped_paths = [line.split(': ')[1].strip() for line in f.readlines()]\n",
    "\n",
    "# Try processing skipped images multiple times\n",
    "for attempt in range(3):\n",
    "    print(f\"\\nAttempt {attempt+1} to process skipped images\")\n",
    "    still_skipped = []\n",
    "    \n",
    "    for img_path in skipped_paths:\n",
    "        try:\n",
    "            # Extract output path based on which input dir contains the image\n",
    "            if original_data_dir in img_path:\n",
    "                base_dir = original_data_dir\n",
    "            elif augmented1_dir in img_path:\n",
    "                base_dir = augmented1_dir\n",
    "            elif augmented2_dir in img_path:\n",
    "                base_dir = augmented2_dir\n",
    "            else:\n",
    "                still_skipped.append(f\"Unknown source dir: {img_path}\")\n",
    "                continue\n",
    "                \n",
    "            rel_path = os.path.relpath(os.path.dirname(img_path), base_dir)\n",
    "            img_name = os.path.basename(img_path)\n",
    "            output_path = os.path.join(output_dir, rel_path, img_name)\n",
    "            \n",
    "            # Create output directory if it doesn't exist\n",
    "            os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "            \n",
    "            # Process image\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is None:\n",
    "                still_skipped.append(f\"Failed to read: {img_path}\")\n",
    "                continue\n",
    "                \n",
    "            rgb_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            faces = detector.detect_faces(rgb_img)\n",
    "            \n",
    "            if not faces:\n",
    "                still_skipped.append(f\"No face: {img_path}\")\n",
    "                continue\n",
    "            \n",
    "            face = max(faces, key=lambda x: x['box'][2] * x['box'][3])\n",
    "            if face['confidence'] < 0.9: # Lower confidence threshold\n",
    "                still_skipped.append(f\"Low confidence: {img_path}\")\n",
    "                continue\n",
    "                \n",
    "            x, y, w, h = face['box']\n",
    "            margin = int(max(w, h) * 0.8) # Increased margin\n",
    "            x1 = max(0, x - margin)\n",
    "            y1 = max(0, y - margin)\n",
    "            x2 = min(img.shape[1], x + w + margin)\n",
    "            y2 = min(img.shape[0], y + h + margin)\n",
    "            cropped = img[y1:y2, x1:x2]\n",
    "            \n",
    "            cv2.imwrite(output_path, cropped)\n",
    "            \n",
    "        except Exception as e:\n",
    "            still_skipped.append(f\"Error processing {img_path}: {str(e)}\")\n",
    "            continue\n",
    "            \n",
    "    skipped_paths = [path for path in still_skipped if not path.startswith(\"Failed to read\")]\n",
    "    print(f\"Remaining skipped images: {len(skipped_paths)}\")\n",
    "    \n",
    "    if not skipped_paths:\n",
    "        break\n",
    "\n",
    "# Write remaining skipped images\n",
    "with open('skipped_images_final.txt', 'w') as f:\n",
    "    f.write('\\n'.join(still_skipped))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlx-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
